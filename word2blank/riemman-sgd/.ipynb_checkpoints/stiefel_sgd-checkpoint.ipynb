{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The code here implements a riemmanian stochastic gradient descent on a Stiefel(orthogonal) Manifold.\n",
    "A brief overview of the maths will be provided. Comments will be there for important lines in the code.\n",
    "The book used for the theory is Optimization Algorithms on Matrix Manifolds by Absil.\n",
    "\n",
    "The SGD itself is a special case of a very generalised line-search method provided in the book called\n",
    "Accelerated Line Search(ALS). An ALS is based on the concept of Retraction to update the x at each step. \n",
    "The retraction formula - \n",
    "x[k+1] = R[x[k]](t[k].eta[k]) where eta[k] is in T[x[k]]M(a tangent vector space at x[k]) and t[k] is a scalar.\n",
    "\n",
    "So, the essential task is to choose a retraction for each x[k] followed by an appropriate step length, t[k] and \n",
    "a search direction, eta[k] at each iteration. However, since we are dealing with Steifel Manifolds alone, the\n",
    "retraction is very easy to define in this case.\n",
    "\n",
    "Our algorithm ALS picks a eta[k] based on a gradient-related sequence and t[k] based on a special point called\n",
    "Armijo step size called t_A[k]. '''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Our space is going to be a steifel manifold, St(p, n) = {X ∈ R n×p : X.T X = Ip } where n=10,p=5\n",
    "#We take an initial point in the space from where we start our iteration for the SGD \n",
    "\n",
    "X_0 =\n",
    "\n",
    "#The continously differentiable scalar field i.e the function we want to minimise\n",
    "f = 5*X**2 + 3*X + 9\n",
    "\n",
    "while True:\n",
    "    #picking eta[k] would be our first task. Our eta[k] in this case is simple: -grad f(x[k-1])= ∇f(W) − W∇f(W).TW\n",
    "    eta[k] = -np.gradient(f,X[k-1]) - X[k-1].\n",
    "    \n",
    "    #next step would be to choose an appropriate step size. Our step size in this case will be the Armijo step size \n",
    "    \n",
    "    #retraction formula used = qfactor of (x+eta[k]t[k]) QR decomposition\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
